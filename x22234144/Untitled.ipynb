{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c073a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    # Read CSV file\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        # Assuming the first row of the CSV file contains headers\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        # Convert CSV data to a list of dictionaries\n",
    "        data = [row for row in csv_reader]\n",
    "\n",
    "    # Write JSON file\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        # Use json.dump() to write the list of dictionaries to JSON\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json('covid.csv', 'covid.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0d9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    # Read CSV file\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        # Assuming the first row of the CSV file contains headers\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        # Convert CSV data to a list of dictionaries\n",
    "        data = [row for row in csv_reader]\n",
    "\n",
    "    # Write JSON file\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        # Use json.dump() to write the list of dictionaries to JSON\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "csv_to_json('FAANG.csv', 'FAANG.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d98244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(json_file_path):\n",
    "    # Open the JSON file for reading\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        # Use json.load() to load the JSON data from the file\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "# Example usage\n",
    "json_data = read_json_file('covid.json')\n",
    "# print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50cbeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def read_json_file(json_file_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "# Example usage\n",
    "json_data = read_json_file('covid.json')\n",
    "\n",
    "# Convert JSON data to a DataFrame\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "\n",
    "# MongoDB connection parameters\n",
    "mongo_uri = 'mongodb+srv://smulani239:Arif2212$@databaseprogramming.eavdhnn.mongodb.net'  # Replace with your MongoDB URI\n",
    "database_name = 'Database'\n",
    "collection_name = 'COVID'\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Convert DataFrame to dictionary and insert into MongoDB\n",
    "records = df.to_dict(orient='records')\n",
    "collection.insert_many(records)\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a03392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def read_json_file(json_file_path):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "# Example usage\n",
    "json_data = read_json_file('FAANG.json')\n",
    "\n",
    "# Convert JSON data to a DataFrame\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# MongoDB connection parameters\n",
    "mongo_uri = 'mongodb+srv://smulani239:Arif2212$@databaseprogramming.eavdhnn.mongodb.net'  # Replace with your MongoDB URI\n",
    "database_name = 'Database'\n",
    "collection_name = 'FAANGS'\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Convert DataFrame to dictionary and insert into MongoDB\n",
    "records = df.to_dict(orient='records')\n",
    "collection.insert_many(records)\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f6471",
   "metadata": {},
   "source": [
    "## Mongo DB URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda86d6",
   "metadata": {},
   "source": [
    "mongodb+srv://smulani239:Arif2212$@databaseprogramming.eavdhnn.mongodb.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2893f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Name of State / UT</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Total Confirmed cases</th>\n",
       "      <th>Death</th>\n",
       "      <th>Cured/Discharged/Migrated</th>\n",
       "      <th>New cases</th>\n",
       "      <th>New deaths</th>\n",
       "      <th>New recovered</th>\n",
       "      <th>total_tests</th>\n",
       "      <th>total_recovered</th>\n",
       "      <th>active_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30-01-2020</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>10.8505</td>\n",
       "      <td>76.2711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>951337</td>\n",
       "      <td>162202</td>\n",
       "      <td>9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31-01-2020</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>10.8505</td>\n",
       "      <td>76.2711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1817530</td>\n",
       "      <td>271826</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-02-2020</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>10.8505</td>\n",
       "      <td>76.2711</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230861</td>\n",
       "      <td>178371</td>\n",
       "      <td>80570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-02-2020</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>10.8505</td>\n",
       "      <td>76.2711</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249838</td>\n",
       "      <td>41021</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-02-2020</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>10.8505</td>\n",
       "      <td>76.2711</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1499795</td>\n",
       "      <td>97149</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Name of State / UT Latitude Longitude Total Confirmed cases  \\\n",
       "0  30-01-2020             Kerala  10.8505   76.2711                     1   \n",
       "1  31-01-2020             Kerala  10.8505   76.2711                     1   \n",
       "2  01-02-2020             Kerala  10.8505   76.2711                     2   \n",
       "3  02-02-2020             Kerala  10.8505   76.2711                     3   \n",
       "4  03-02-2020             Kerala  10.8505   76.2711                     3   \n",
       "\n",
       "  Death Cured/Discharged/Migrated New cases New deaths New recovered  \\\n",
       "0     0                         0         0          0             0   \n",
       "1     0                         0         0          0             0   \n",
       "2     0                         0         1          0             0   \n",
       "3     0                         0         1          0             0   \n",
       "4     0                         0         0          0             0   \n",
       "\n",
       "  total_tests total_recovered active_cases  \n",
       "0      951337          162202         9375  \n",
       "1     1817530          271826          251  \n",
       "2      230861          178371        80570  \n",
       "3      249838           41021          982  \n",
       "4     1499795           97149          145  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection parameters\n",
    "mongo_uri = 'mongodb+srv://smulani239:Arif2212$@databaseprogramming.eavdhnn.mongodb.net/'  # Replace with your MongoDB URI\n",
    "database_name = 'Database'\n",
    "collection_name = 'COVID'\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Fetch data from MongoDB collection\n",
    "cursor = collection.find({})\n",
    "\n",
    "# Convert MongoDB cursor to DataFrame\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n",
    "\n",
    "df = df.drop('_id', axis=1)\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b379228a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# MongoDB connection parameters\n",
    "mongo_uri = 'mongodb+srv://smulani239:Arif2212$@databaseprogramming.eavdhnn.mongodb.net/'  # Replace with your MongoDB URI\n",
    "database_name = 'Database'\n",
    "collection_name = 'FAANGS'\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Fetch data from MongoDB collection\n",
    "cursor = collection.find({})\n",
    "\n",
    "# Convert MongoDB cursor to DataFrame\n",
    "df = pd.DataFrame(list(cursor))\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n",
    "\n",
    "df = df.drop('_id', axis=1)\n",
    "# Display the DataFrame\n",
    "\n",
    "# Set up PostgreSQL connection\n",
    "username = 'postgres'\n",
    "password = 'root'\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "database = 'Stocks'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# Insert data into PostgreSQL\n",
    "table_name = 'FAANG'\n",
    "df.to_sql(table_name, engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da8533e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://postgres:***@localhost:5432/Stocks)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'OptionEngine' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(engine)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Insert data into PostgreSQL\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# query = 'SELECT * FROM FAANG'\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFAANG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\io\\sql.py:288\u001b[0m, in \u001b[0;36mread_sql_table\u001b[1;34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(table_name):\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 288\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\io\\sql.py:1457\u001b[0m, in \u001b[0;36mSQLDatabase.read_table\u001b[1;34m(self, table_name, index_col, coerce_float, parse_dates, columns, schema, chunksize)\u001b[0m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;124;03mRead SQL database table into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1454\u001b[0m \n\u001b[0;32m   1455\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1456\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(table_name, \u001b[38;5;28mself\u001b[39m, index\u001b[38;5;241m=\u001b[39mindex_col, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[1;32m-> 1457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\io\\sql.py:1000\u001b[0m, in \u001b[0;36mSQLTable.read\u001b[1;34m(self, coerce_float, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    998\u001b[0m     sql_select \u001b[38;5;241m=\u001b[39m select(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable) \u001b[38;5;28;01mif\u001b[39;00m _gt14() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mselect()\n\u001b[1;32m-> 1000\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1001\u001b[0m column_names \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\lib\\site-packages\\pandas\\io\\sql.py:1402\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnectable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'OptionEngine' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "username = 'postgres'\n",
    "password = 'root'\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "database = 'Stocks'\n",
    "\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "print(engine)\n",
    "\n",
    "# Insert data into PostgreSQL\n",
    "# query = 'SELECT * FROM FAANG'\n",
    "df = pd.read_sql_table('FAANG', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44049e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyscopg2 in c:\\python\\lib\\site-packages (66.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pyscopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyscopg2\n",
    "\n",
    "conn = pyscopg2.connect(host = \"localhost\", dbname = \"stocks\", user=\"postgres\", \n",
    "                        password = \"root\", port = 5432)\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ecaa7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Insert data into PostgreSQL\u001b[39;00m\n\u001b[0;32m     15\u001b[0m table_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFAANG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_sql(table_name, engine, if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aff7902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.23-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python\\lib\\site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\lib\\site-packages (from sqlalchemy) (1.1.2)\n",
      "Downloading SQLAlchemy-2.0.23-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.7/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 8.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sqlalchemy\n",
      "Successfully installed sqlalchemy-2.0.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96088cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp310-cp310-win_amd64.whl.metadata (4.5 kB)\n",
      "Downloading psycopg2-2.9.9-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.5/1.2 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.1/1.2 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f80a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\python\\lib\\site-packages (2.0.23)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python\\lib\\site-packages (from sqlalchemy) (4.8.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\python\\lib\\site-packages (from sqlalchemy) (1.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1668e0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
